{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Task_2_Rap_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctWmp1ZqIbNa",
        "colab_type": "text"
      },
      "source": [
        "#### A final table with perplexity values for different models is provided below the application of different models.\n",
        "***\n",
        "#### At the end of the file there is an attempt to use Markov chain and links to sources, which were used in this work\n",
        "***\n",
        "#### Some examples of lyrics generation are provided (unfortunately, not for all LMs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g5bvGNvI6tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import sys\n",
        "#!{sys.executable} -m pip install nltk==3.5b1\n",
        "#!{sys.executable} -m pip install lyricsgenius"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "j1I6-5fBIbNb",
        "colab_type": "code",
        "outputId": "3df9e5e1-2783-410e-dbf3-6183fbd630a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import lyricsgenius\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "nltk.download('punkt')\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.lm import KneserNeyInterpolated \n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk import word_tokenize, sent_tokenize \n",
        "import textwrap"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4q4xlKIbNf",
        "colab_type": "text"
      },
      "source": [
        "#### The chunk below was commented after the work was done in order not to waste space on GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DxpbDqQEIbNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking whether installed module works correctly, setting Eminem as the author\n",
        "genius = lyricsgenius.Genius(\"jHJB8vqrbfVDIGM1KrETFx6s7EG9SGN3RGcmr63z7Gjgz8dYY4LizTL9rGupTAl1\")\n",
        "#at first used to sort by title, but it brings remixes of same song, so let us sort by popularity \n",
        "#Eminem = genius.search_artist(\"Eminem\", max_songs=300, sort=\"popularity\")\n",
        "genius.remove_section_headers = True\n",
        "genius.skip_non_songs = False \n",
        "genius.verbose = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQNINerQrsrm",
        "colab_type": "text"
      },
      "source": [
        "#### At first I used only 300 Eminem's songs, and got pretty high perplexity. Then it was decided to expand the set in order to get better perplexity, so below I append  the lyrics of 50 Cent, since the Internet told me they are quite similar to Eminem's.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24j5fO7NL-Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading 50 Cent lyrics to extend the vocabulary\n",
        "genius = lyricsgenius.Genius(\"jHJB8vqrbfVDIGM1KrETFx6s7EG9SGN3RGcmr63z7Gjgz8dYY4LizTL9rGupTAl1\")\n",
        "#Cent_50 = genius.search_artist(\"50 Cent\", max_songs=200, sort=\"popularity\")\n",
        "genius.remove_section_headers = True\n",
        "genius.skip_non_songs = False \n",
        "genius.verbose = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE36c5tPIbNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8781c4b9-2bad-46aa-af96-a0d40e3cee7c"
      },
      "source": [
        "Eminem.save_lyrics(extension='txt')\n",
        "Cent_50.save_lyrics(extension='txt')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote `Lyrics_Eminem.txt`\n",
            "Wrote `Lyrics_50Cent.txt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBn8tfmmIbNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opening of files and tokenization\n",
        "#at first I intended to delete the punctuation, but then decided to leave it since rap lyrics will look more interesting with punctuation\n",
        "#however, maybe, it was a wrong decision\n",
        "lyrics_em = open(\"Lyrics_Eminem.txt\",\"r\")\n",
        "lyrics_cent = open(\"Lyrics_50Cent.txt\",\"r\")\n",
        "token_lyrics_em = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in lyrics_em]\n",
        "token_lyrics_cent = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in lyrics_cent]\n",
        "lyrics = []\n",
        "lyrics.extend(token_lyrics_em)\n",
        "lyrics.extend(token_lyrics_cent)                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYQT8DZTIbNt",
        "colab_type": "code",
        "outputId": "14416031-f49b-406a-b58c-c0997eb27d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "flattened_list = []\n",
        "for x in lyrics:\n",
        "    for y in x:\n",
        "        flattened_list.append(y)\n",
        "stopwords=['intro', 'verse', 'chorus','!','\"', \"'\", 'â€™', '#','$','%','&','(',')','*','+',',','-','/',':',';','<','=','>','?','@','[','\\\\',']',\n",
        " '^','_','`','{','|','}','~', '1', '...', \"'s\",\"'m\", \"n't\" ]\n",
        "for word in flattened_list:\n",
        "    if word in stopwords:\n",
        "        flattened_list.remove(word)\n",
        "word_count = Counter(flattened_list).most_common(20)\n",
        "word_count_df = pd.DataFrame(word_count, columns = ['word', 'count'])\n",
        "\n",
        "#creating a plot, depicting words distribution\n",
        "fig, (ax) = plt.subplots(figsize = (10, 4))\n",
        "sns.barplot(x = word_count_df['word'], y = word_count_df['count'], ax = ax)\n",
        "ax.set_ylabel('count', fontsize = 10)\n",
        "ax.set_xlabel('word',fontsize = 10)\n",
        "ax.tick_params(labelsize=10)\n",
        "ax.set_title('Top 20 word in Eminem rap lyrics', fontsize = 15)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Top 20 word in Eminem rap lyrics')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gykVaTc_IbNw",
        "colab_type": "text"
      },
      "source": [
        "#### As we know, the bigger is testset, the better, therefore let's set the size of at least 40%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9AlvkhYIbNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(lyrics, test_size=0.4, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVKlwwOvb49e",
        "colab_type": "text"
      },
      "source": [
        "#### Since this version of my work is done in Google Colaboratory (which disconnects all the time) and each chunk with text generation takes about 2 hours to execute, the examples of text generation is be provided not for every type of ngrams and model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xCrrr2hIbN7",
        "colab_type": "text"
      },
      "source": [
        "### 1-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpC4pmUjIbN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF4v5XqYIbN-",
        "colab_type": "text"
      },
      "source": [
        "#### Kneser-Ney Interpolated for unigrams, default value of discount = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtJcYiTMIbN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_1_KN, padded_sents_1_KN = padded_everygram_pipeline(n, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho5mj0dfIbOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1_KN = KneserNeyInterpolated(n, discount=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tloONy_fIbOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1_KN.fit(train_data_1_KN, padded_sents_1_KN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uupOSvb-F_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_uni,_ = padded_everygram_pipeline(n, test)\n",
        "test_uni = []\n",
        "for i in test_data_uni:\n",
        "  test_uni.extend(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlyHk5K8IbOF",
        "colab_type": "code",
        "outputId": "fcabd9cf-48bc-4332-e211-fa551b93c364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Unigram_KN_PP_01 = model_1_KN.perplexity(test_uni)\n",
        "Unigram_KN_PP_01"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14245.000000168671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-nZyLT2IbOI",
        "colab_type": "text"
      },
      "source": [
        "#### Kneser-Ney Interpolated for unigrams, set value of discount = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hIuZpUvIbOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_9_KN, padded_sents_9_KN = padded_everygram_pipeline(n, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAZgtgnhIbOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1_KN_9 = KneserNeyInterpolated(n, discount=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_SVV8SAIbOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1_KN_9.fit(train_data_9_KN, padded_sents_9_KN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvnAZquRIbOQ",
        "colab_type": "code",
        "outputId": "3a16fd25-5364-4481-d986-cfcc699d1344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Unigram_KN_PP_09 = model_1_KN_9.perplexity(test_uni)\n",
        "Unigram_KN_PP_09"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14245.000000168671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BQ8wUUNuIbOS",
        "colab_type": "code",
        "outputId": "1342631b-2147-42aa-fdee-00d36cf1d7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model_1_KN_9.generate(10, random_seed=1))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bulimic', 'stove', 'scrubs', 'dickâ€”shit', 'lama', 'incompatible', 'philosophies', 'shrunk', 'betrayed', 'adderall']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ4Ho0mUIbOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As we can see above, simple generation shows separate words, therefore, new function is included below\n",
        "#which is fully copypasted from https://www.kaggle.com/alvations/n-gram-language-model-with-nltk\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH2RwI-DIbOX",
        "colab_type": "code",
        "outputId": "be0dcd8c-3dcd-46b3-bcd8-4ed259e75300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "for i in range(3):\n",
        "    print(generate_sent(model_1_KN_9, 10, random_seed=i))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stock scarlata hide-and-seek dip lightin handed- shooby-de-doo-wop entitled jukes murderin\n",
            "bulimic stove scrubs dickâ€”shit lama incompatible philosophies shrunk betrayed adderall\n",
            "walked villian arrested beanies standpoint roast porcelain eternal nurse nwa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpFz8GiJIbOa",
        "colab_type": "text"
      },
      "source": [
        "#### Laplace model for unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su2DlUE2IbOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_LA, padded_sents_LA = padded_everygram_pipeline(n, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7COZHkKZIbOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace = Laplace(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdExj_aEIbOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace.fit(train_data_LA, padded_sents_LA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVdp3syaIbOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bffdb39-b916-421e-eef4-c7e70dc1b780"
      },
      "source": [
        "Unigram_laplace_PP = model_laplace.perplexity(test_uni)\n",
        "Unigram_laplace_PP"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573.0987302488888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFcVdQyIbOm",
        "colab_type": "code",
        "outputId": "5d38cac8-aa34-4a34-978d-903435f328ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Let's look at examples of text generation\n",
        "for i in range(3):\n",
        "    print(generate_sent(model_laplace, 10, random_seed=i))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "them shit hair bitch into goin spit comb i man\n",
            "- there shuck better idea how nigga stayin, 'em\n",
            "wrapped with's, the round of cool mink mistake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1bRLcETIbOp",
        "colab_type": "text"
      },
      "source": [
        "#### MLE for unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ViiLPNHIbOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_MLE, padded_sents_MLE = padded_everygram_pipeline(n, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lam9hW_UIbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE = MLE(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXYnefcaIbOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE.fit(train_data_MLE, padded_sents_MLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0VnpCldIbOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9ac305d-b60b-4262-b25a-bd1f283b4663"
      },
      "source": [
        "#Unfortunately, it is infinite because of unknowkn n-grams in test set\n",
        "Unigram_mle_PP = model_MLE.perplexity(test_uni)\n",
        "Unigram_mle_PP"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnj-wHEdIbO0",
        "colab_type": "code",
        "outputId": "81190904-3705-4797-88c1-7a04ba50fd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Let's look at examples of text generation\n",
        "for i in range(3):\n",
        "    print(generate_sent(model_MLE, 10, random_seed=i))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there shit had beef in go stand chorus i make\n",
            ", they simple be i hour nigga stomping, 'd\n",
            "y'all with's, the rrarrrrh of cock mic migraines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmglC6L6IbO2",
        "colab_type": "text"
      },
      "source": [
        "### 2-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNCOMOGZIbO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNKukEUzcPNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_bi,_ = padded_everygram_pipeline(2, test)\n",
        "test_bi = []\n",
        "for i in test_data_bi:\n",
        "  test_bi.extend(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEy69p7yIbO5",
        "colab_type": "text"
      },
      "source": [
        "#### Kneser-Ney Interpolated for bigrams, default value of discount = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u1h_Q_pjqEu",
        "colab_type": "text"
      },
      "source": [
        "As our previous experience shows us, setting different discounts has no effect, so we will look only at default value of d=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtMURe0EIbO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_1_KN_2, padded_sents_1_KN_2 = padded_everygram_pipeline(m, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9MWPFOmIbO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2_KN = KneserNeyInterpolated(m, discount=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9vHGjUjIbO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2_KN.fit(train_data_1_KN_2, padded_sents_1_KN_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy1E6Y0OIbPA",
        "colab_type": "code",
        "outputId": "295fadbf-b3d0-4b85-f343-3eb13122d15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Bigram_KN_PP_01 = model_2_KN.perplexity(test_bi)\n",
        "Bigram_KN_PP_01"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1931.916190986568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eew9CN16IbPW",
        "colab_type": "text"
      },
      "source": [
        "#### Laplace model for bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGobqWPxIbPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_LA_2, padded_sents_LA_2 = padded_everygram_pipeline(m, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4jHooeNIbPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace_2 = Laplace(m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4YkLECAIbPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace_2.fit(train_data_LA_2, padded_sents_LA_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbTcFD4nIbPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2d2f638-7ed1-4048-e165-2ebd8e082e10"
      },
      "source": [
        "Bigram_laplace_PP = model_laplace_2.perplexity(test_bi)\n",
        "Bigram_laplace_PP"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571.0400319718012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alGjpr_sIbPm",
        "colab_type": "code",
        "outputId": "2fe306bc-fd23-4764-b69b-36a0d28c0d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Let's look at examples of text generation\n",
        "for i in [5,6,7,8]:\n",
        "    print(generate_sent(model_laplace_2, 10, random_seed=i))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "know what we want to too )\n",
            "shady murdered my exhaust\n",
            "actin' off, look at\n",
            "you, secret, freeze your caps and it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMsmpeaDIbPo",
        "colab_type": "text"
      },
      "source": [
        "#### MLE for bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFRewlSsIbPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_MLE_2, padded_sents_MLE_2 = padded_everygram_pipeline(m, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU9zWrGKIbPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE_2 = MLE(m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp2j3gIWIbPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE_2.fit(train_data_MLE_2, padded_sents_MLE_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnhZBoy1IbPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bb85e8c-d9e5-4d37-ec5e-c746298f708f"
      },
      "source": [
        "Bigram_mle_PP=model_MLE_2.perplexity(test_bi)\n",
        "Bigram_mle_PP"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y-_vX3RIbPy",
        "colab_type": "code",
        "outputId": "d73a56da-8f63-4a4e-8f8f-df6ac3d10ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Let's look at examples of text generation via MLE for bigrams\n",
        "for i in [8,10,11]:\n",
        "    print(generate_sent(model_MLE_2, 10, random_seed=i))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you, shady's constant controversy\n",
            "i can look\n",
            "don't wannahold the corny shit for the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCnetAgTIbP0",
        "colab_type": "text"
      },
      "source": [
        "### 3-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq0AnBpmIbP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5hj_3yrjXow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_tri,_ = padded_everygram_pipeline(3, test)\n",
        "test_tri = []\n",
        "for i in test_data_tri:\n",
        "  test_tri.extend(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpnKnkyZIbP2",
        "colab_type": "text"
      },
      "source": [
        "#### Kneser-Ney Interpolated for trigrams, default value of discount = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4xhuCh8IbP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_1_KN_3, padded_sents_1_KN_3 = padded_everygram_pipeline(t, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtgT3ZnIbP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3_KN = KneserNeyInterpolated(t, discount=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm_Ipw8pIbP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3_KN.fit(train_data_1_KN_3, padded_sents_1_KN_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8UCFVj_IbP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "891bcf27-756b-4534-d5e5-66724453a100"
      },
      "source": [
        "Trigram_KN_PP = model_3_KN.perplexity(test_tri)\n",
        "Trigram_KN_PP"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "694.172686122184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "694.172686122184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_rMiU-WIbP-",
        "colab_type": "text"
      },
      "source": [
        "#### Laplace model for trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTw09kccIbP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_LA_3, padded_sents_LA_3 = padded_everygram_pipeline(t, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVhW6brfIbQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace_3 = Laplace(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00j35kXgIbQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_laplace_3.fit(train_data_LA_3, padded_sents_LA_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIWmTeK2IbQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b21a5e42-aa0e-4c6e-e603-e6a7574d4e8f"
      },
      "source": [
        "Trigram_laplace_PP = model_laplace_3.perplexity(test_tri)\n",
        "Trigram_laplace_PP"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "560.8963894791663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd_Q3d7CIbQL",
        "colab_type": "text"
      },
      "source": [
        "#### MLE for trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO4CHhh7IbQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_MLE_3, padded_sents_MLE_3 = padded_everygram_pipeline(t, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2L-h_WyIbQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE_3 = MLE(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi2XVBRhIbQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLE_3.fit(train_data_MLE_3, padded_sents_MLE_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs1FRsMtIbQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42b68059-da17-46de-a723-3ba96c0ecc3f"
      },
      "source": [
        "Trigram_mle_PP = model_MLE_3.perplexity(test_tri)\n",
        "Trigram_mle_PP"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrn3L-FGIbQR",
        "colab_type": "code",
        "outputId": "ed719f6d-d395-4748-dd9c-7463d3fab917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Let's look at examples of text generation via MLE for trigrams\n",
        "for i in [34,5,18]:\n",
        "    print(generate_sent(model_MLE_3, 10, random_seed=i))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "don't wannasmoke but ain't gon '\n",
            "i may have never made recovery, kid rock and\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYrkMOTBIbQT",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a table with results for each of n-grams (I write values manually because Google Colaboratory disconnects all the time, and previously determined variable become invalid (and perplexity take minimum 1h to be counted). So I just fill in manually the tables with values that you have seen before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D06SaXyeIbQU",
        "colab_type": "code",
        "outputId": "a0e4ac29-e69e-429f-d6d5-5adbc99343f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "compare = {'N-grams':['1-gram', '2-gram', '3-gram'],\n",
        "        'Kneser-Ney PP': ['14245','1932','694'],\n",
        "        'Laplace PP': ['573','571','561'],\n",
        "        'MLE PP': ['inf','inf', 'inf'] }\n",
        "models = pd.DataFrame(compare, columns = ['N-grams', 'Kneser-Ney PP', 'Laplace PP', 'MLE PP'])\n",
        "models_perplexity = models.style.set_table_styles([{'selector':'','props':[('border','4px solid #7a7'), ('font-family', 'verdana'),('font-family', 'verdana'), ('font-size', '105%')]}])\n",
        "models_perplexity"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002  {\n",
              "          border: 4px solid #7a7;\n",
              "          font-family: verdana;\n",
              "          font-family: verdana;\n",
              "          font-size: 105%;\n",
              "    }</style><table id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >N-grams</th>        <th class=\"col_heading level0 col1\" >Kneser-Ney PP</th>        <th class=\"col_heading level0 col2\" >Laplace PP</th>        <th class=\"col_heading level0 col3\" >MLE PP</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1-gram</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row0_col1\" class=\"data row0 col1\" >14245</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row0_col2\" class=\"data row0 col2\" >573</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row0_col3\" class=\"data row0 col3\" >inf</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row1_col0\" class=\"data row1 col0\" >2-gram</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1932</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row1_col2\" class=\"data row1 col2\" >571</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row1_col3\" class=\"data row1 col3\" >inf</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row2_col0\" class=\"data row2 col0\" >3-gram</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row2_col1\" class=\"data row2 col1\" >694</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row2_col2\" class=\"data row2 col2\" >561</td>\n",
              "                        <td id=\"T_078c2b1e_7c74_11ea_a9f6_0242ac1c0002row2_col3\" class=\"data row2 col3\" >inf</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f8b61788a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3bRqyVxIbQV",
        "colab_type": "text"
      },
      "source": [
        "#### <span style=\"color:green\">*Conclusion*</span>: In this version of my work lyrics were devided by sentences, and tokenization was executed in the other manner. However, the models were the same, their quality is much better! Maybe if I used more songs, they would be even better, and perplexity would be lower. Still tuning of discount value for Kneser-Ney had no effect on perplexity, all models showed different values of perplexity, which was decreasing while n for ngrams was increasing. Laplace LM showed better results, but we can see how perplexity values for Laplace and Kneser-Ney models become closer with increasing of n (and also we know that Laplace is not perfect for human-like texts). Generated texts leave much to be desired, though. Unfortunately, I had no opportunity to generate rap for every LM because of my computer's limitations. Despite it took all my night before the deadline, getting lower perplexity values was worth it. Yo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQcY_Q0bIbQV",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SHGiDjoIbQX",
        "colab_type": "text"
      },
      "source": [
        "### Below there is an attempt to use principle of Markov chains for lyrics generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dflyJepIbQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_text = lyricsdf['lyr_token'].tolist()\n",
        "flattened_lyr = []\n",
        "for x in tokenized_text:\n",
        "    for y in x:\n",
        "        flattened_lyr.append(y)\n",
        "\n",
        "def make_bigrams(text):\n",
        "    for i in range(len(text)-1):\n",
        "        yield (text[i], text[i+1])\n",
        "        \n",
        "bigrams = make_bigrams(flattened_lyr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm6t-gkGIbQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "\n",
        "for word_1, word_2 in bigrams:\n",
        "    if word_1 in word_dict.keys():\n",
        "        word_dict[word_1].append(word_2)\n",
        "    else:\n",
        "        word_dict[word_1] = [word_2]\n",
        "        \n",
        "first_word = np.random.choice(flattened_lyr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3njviBRJIbQZ",
        "colab_type": "code",
        "outputId": "add8feec-f76a-4ba1-d8fd-1e5a8a828c46",
        "colab": {}
      },
      "source": [
        "while first_word.islower():\n",
        "    first_word = np.random.choice(flattened_lyr)\n",
        "\n",
        "chain = [first_word]\n",
        "n_words = 100\n",
        "\n",
        "for i in range(n_words):\n",
        "    chain.append(np.random.choice(word_dict[chain[-1]]))\n",
        "\n",
        "generated_text = ' '.join(chain)\n",
        "rap = textwrap.fill(generated_text, width=50)\n",
        " \n",
        "print(rap)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 met this fucking chick is to hurt you cave in\n",
            "the pot make us together everything is on riding\n",
            "on it trying to run deep as i had them some twins\n",
            "before they say that i need somethin to outrun me\n",
            "to toe from amityville hell stab in the panelin\n",
            "cussin no paper i know where must go to think of\n",
            "evil as i apologize if i have no help propel me\n",
            "only women skinning your mom your verdict while i\n",
            "get to dust and did you pissed me and if ten\n",
            "freaky girls man ya sweeter than an mc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31UMqGYtIbQb",
        "colab_type": "text"
      },
      "source": [
        "#### Unfortunately, I have no clue how to evaluate the quality of text generation, provided by this method. As far as I can judge, lyrics are not that bad, since there are many pairs and triples of words commonly used together, and some lines even make sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YfOp52rIbQb",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7Cbs3GIbQg",
        "colab_type": "text"
      },
      "source": [
        "Heavily based on:\n",
        "    https://www.kaggle.com/alvations/n-gram-language-model-with-nltk and https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6"
      ]
    }
  ]
}