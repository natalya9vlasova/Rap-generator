{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Forest_Gump\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import lyricsgenius\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "nltk.download('punkt')\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.lm import KneserNeyInterpolated as KNI\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk import word_tokenize, sent_tokenize \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Eminem...\n",
      "\n",
      "Song 1: \".\"\n",
      "Song 2: \"12 Days of Diss-Mas\"\n",
      "Song 3: \"1-833-2GET-REV (REVIVAL Voicemail)\"\n",
      "Song 4: \"1996 Underground Freestyle\"\n",
      "Song 5: \"1997 Freestyle Live at Wetlands, NYC\"\n",
      "Song 6: \"1997 Rap Olympics\"\n",
      "Song 7: \"1999\"\n",
      "Song 8: \"1999 Tim Westwood Freestyle\"\n",
      "Song 9: \"2004 Tim Westwood Freestyle\"\n",
      "Song 10: \"2012 Something From Nothing: Art of Rap Freestyle\"\n",
      "Song 11: \"2.0 Boys\"\n",
      "Song 12: \"25 To Life\"\n",
      "Song 13: \"313\"\n",
      "Song 14: \"3 a.m.\"\n",
      "Song 15: \"3 Verses\"\n",
      "Song 16: \"4 Verses\"\n",
      "Song 17: \"50 Ways\"\n",
      "Song 18: \"8 Mile\"\n",
      "Song 19: \"8 Mile: 313 Cypher (Chin Tiki Girls)\"\n",
      "Song 20: \"8 Mile Background Music\"\n",
      "Song 21: \"8 Mile: B-Rabbit vs Papa Doc\"\n",
      "Song 22: \"8 Mile: B-Rabbit vs Supa Emcee\"\n",
      "Song 23: \"8 Mile: Cheddar Bob Freestyle\"\n",
      "Song 24: \"8 Mile: D’Phuzion vs B-Rabbit\"\n",
      "Song 25: \"8 Mile: Lily’s Lullaby\"\n",
      "Song 26: \"8 Mile: Lotto vs B-Rabbit\"\n",
      "Song 27: \"8 Mile: Lyckety-Splyt vs B-Rabbit\"\n",
      "Song 28: \"8 Mile: Marv Won vs B-Rabbit\"\n",
      "Song 29: \"8 Mile: Maurice Grant vs B-Rabbit\"\n",
      "Song 30: \"8 Mile: Sweet Home Alabama Freestyle\"\n",
      "Song 31: \"8 Mile: The Lunch Truck Battle\"\n",
      "Song 32: \"’97 Blazer\"\n",
      "Song 33: \"97' Bonnie & Clyde\"\n",
      "Song 34: \"’99 Tim Westwood Freestyle\"\n",
      "Song 35: \"Alfred (Interlude)\"\n",
      "Song 36: \"Alfred (Outro)\"\n",
      "Song 37: \"Almost Famous\"\n",
      "Song 38: \"Amityville\"\n",
      "Song 39: \"Anger Management\"\n",
      "Song 40: \"Anger Management (Turkish Translation)\"\n",
      "Song 41: \"Any Man (Fucking Crazy)\"\n",
      "Song 42: \"Any Word Freestyle\"\n",
      "Song 43: \"Ariel\"\n",
      "Song 44: \"Armaggedon (The Invasion Part 3)\"\n",
      "Song 45: \"Arose\"\n",
      "Song 46: \"Asshole\"\n",
      "Song 47: \"Ass Like That\"\n",
      "Song 48: \"As the World Turns\"\n",
      "Song 49: \"Aye Yo, use this link\"\n",
      "Song 50: \"Baby\"\n",
      "Song 51: \"Backstabber\"\n",
      "Song 52: \"Bad Guy\"\n",
      "Song 53: \"Bad Husband\"\n",
      "Song 54: \"Bad Influence\"\n",
      "Song 55: \"Bad Meets Evil\"\n",
      "Song 56: \"Bad Meets Evil Original\"\n",
      "Song 57: \"Bagpipes from Baghdad\"\n",
      "Song 58: \"Ballin’ Uncontrollably\"\n",
      "Song 59: \"Baruch College Session\"\n",
      "Song 60: \"Beautiful\"\n",
      "Song 61: \"Beautiful Pain\"\n",
      "Song 62: \"Beautiful (Radio Edit)\"\n",
      "Song 63: \"Believe\"\n",
      "\"Benzino II (Skit)\" is not valid. Skipping.\n",
      "Song 64: \"Berzerk\"\n",
      "Song 65: \"Berzerk Explained\"\n",
      "Song 66: \"BET Shady 2.0 Cypher\"\n",
      "Song 67: \"Big Weenie\"\n",
      "Song 68: \"Bitch Please II\"\n",
      "\"Bitch (Skit)\" is not valid. Skipping.\n",
      "\"Bizarre (Skit) [2004]\" is not valid. Skipping.\n",
      "Song 69: \"Bjorn Ironside\"\n",
      "Song 70: \"Brain Damage\"\n",
      "Song 71: \"Brain Damage (Snippet)\"\n",
      "Song 72: \"Brainless\"\n",
      "Song 73: \"Breaking News\"\n",
      "Song 74: \"Breaking News - Intro\"\n",
      "Song 75: \"Brenda\"\n",
      "Song 76: \"Broke Day (Snippet of ”It’s Okay”)\"\n",
      "Song 77: \"Broken Rubber\"\n",
      "Song 78: \"Buffalo Bill\"\n",
      "Song 79: \"Bully\"\n",
      "Song 80: \"Bump Heads - DJ Green Lantern Version\"\n",
      "Song 81: \"Bump Heads (Ja Rule Diss)\"\n",
      "Song 82: \"Business\"\n",
      "Song 83: \"Business (A Cappella)\"\n",
      "Song 84: \"Business - Live At The Palace of Auburn Hills, Detroit / 2002\"\n",
      "Song 85: \"Campaign Speech\"\n",
      "Song 86: \"Cancerous (Freestyle)\"\n",
      "Song 87: \"Can I Bitch (Canibus Diss)\"\n",
      "Song 88: \"Careful What You Wish For\"\n",
      "Song 89: \"Castle\"\n",
      "Song 90: \"Celebrity (Freestyle)\"\n",
      "Song 91: \"Chloraseptic\"\n",
      "Song 92: \"Chloraseptic (Remix)\"\n",
      "Song 93: \"Cinderella Man\"\n",
      "Song 94: \"Cleanin’ Out My Closet\"\n",
      "Song 95: \"Cleanin’ Out My Closet (Drum & Bass Remix)\"\n",
      "\"Cleanin’ Out My Closet (Instrumental)\" is not valid. Skipping.\n",
      "Song 96: \"C’mon Everybody\"\n",
      "Song 97: \"Cocaine\"\n",
      "Song 98: \"Cock Massage\"\n",
      "Song 99: \"Cold Wind Blows\"\n",
      "Song 100: \"Countdown\"\n",
      "\n",
      "Reached user-specified song limit (100).\n",
      "Done. Found 100 songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking whether installed module works correctly, setting Eminem as the author\n",
    "genius = lyricsgenius.Genius(\"jHJB8vqrbfVDIGM1KrETFx6s7EG9SGN3RGcmr63z7Gjgz8dYY4LizTL9rGupTAl1\")\n",
    "artist = genius.search_artist(\"Eminem\", max_songs=100, sort=\"title\")\n",
    "genius.remove_section_headers = True\n",
    "genius.verbose = False\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics_Eminem.json already exists. Overwrite?\n",
      "(y/n): y\n",
      "Wrote `Lyrics_Eminem.json`\n"
     ]
    }
   ],
   "source": [
    "artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alternate_names', 'api_path', 'description', 'facebook_name', 'followers_count', 'header_image_url', 'id', 'image_url', 'instagram_name', 'is_meme_verified', 'is_verified', 'name', 'translation_artist', 'twitter_name', 'url', 'current_user_metadata', 'iq', 'description_annotation', 'user', 'songs'])\n"
     ]
    }
   ],
   "source": [
    "lyrics = 'Lyrics_Eminem.json'\n",
    "with open(lyrics) as eminem_lyrics:\n",
    "    messyvocab = json.load(eminem_lyrics)\n",
    "dict_keys = messyvocab.keys()\n",
    "print(dict_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. \"Hit 'Em Up\" by 2Pac (Ft. Outlawz)\\n2. \"Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Automated Voice]\\nThank you for your interest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Song lyrics\n",
       "0                                                  /\n",
       "1  1. \"Hit 'Em Up\" by 2Pac (Ft. Outlawz)\\n2. \"Dis...\n",
       "2  [Automated Voice]\\nThank you for your interest..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = messyvocab.get('songs')\n",
    "lyrics_vocab = []\n",
    "for i in range(0,len(vocab)):\n",
    "    index = vocab[i]\n",
    "    song = index.get('lyrics')\n",
    "    lyrics_vocab.append(song)\n",
    "lyricsdf = pd.DataFrame(lyrics_vocab, columns=['Song lyrics'])\n",
    "lyricsdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "lyricsdf = lyricsdf.dropna()\n",
    "print(len(lyricsdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['!','\"','#','$','%','&','(',')','*','+',',','-','/',':',';','<','=','>','?','@','[','\\\\',']',\n",
    " '^','_','`','{','|','}','~', '46', '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(lyricsdf)):\n",
    "    stringlyric = lyricsdf.iloc[i,0]\n",
    "    stringlyric.replace(\"\\n\\n\\n\\n\\n\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\\n\\n\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\\n\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\n\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\\\n\", \"\\n\")\n",
    "    stringlyric.replace(\"\\\\\", \"\\n\")\n",
    "    for x in punctuation: \n",
    "        stringlyric = stringlyric.replace(x, '')\n",
    "        lyricsdf.iloc[i,0] = stringlyric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(lyricsdf, test_size=0.7, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = str(train['Song lyrics'])\n",
    "tr = tr.lower()\n",
    "splitted = tr.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change discount later\n",
    "paddedLine = [list(pad_both_ends(word_tokenize(tr), n=2))]\n",
    "trainset, vocab = padded_everygram_pipeline(2, paddedLine)\n",
    "lm = KNI(2,discount=0.1);\n",
    "lm.fit(trainset,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('46', 'intro\\\\nwow'), ('intro\\\\nwow', 'baby\\\\n\\\\nchorus\\\\nthe'), ('baby\\\\n\\\\nchorus\\\\nthe', 'way'), ('way', 'you'), ('you', 'shake'), ('shake', 'i'), ('i', '...'), ('...', '49'), ('49', 'verse'), ('verse', '1\\\\none'), ('1\\\\none', 'thousand'), ('thousand', 'different'), ('different', 'houses'), ('houses', 'and'), ('and', 'mün'), ('mün', '...'), ('...', '22'), ('22', 'brabbit'), ('brabbit', 'eminem\\\\ncheddar'), ('eminem\\\\ncheddar', 'i'), ('i', 'can'), ('can', 'rip'), ('rip', 'you'), ('you', 'to'), ('to', 'a'), ('a', 'shr'), ('shr', '...'), ('...', '58'), ('58', 'bust'), ('bust', 'it\\\\nthe'), ('it\\\\nthe', 'final'), ('final', 'problem'), ('problem', 'is'), ('is', 'solved'), ('solved', 'by'), ('by', 'throwi'), ('throwi', '...'), ('...', '41'), ('41', 'all'), ('all', 'i'), ('i', 'got'), ('got', 'to'), ('to', 'do'), ('do', 'is'), ('is', 'throw'), ('throw', 'any'), ('any', 'word'), ('word', 'at'), ('at', 'you'), ('you', 'you'), ('you', 'c'), ('c', '...'), ('...', '...'), ('...', '14'), ('14', 'intro\\\\nit'), ('intro\\\\nit', \"'s\"), (\"'s\", 'like'), ('like', 'this'), ('this', 'and'), ('and', 'like'), ('like', 'that'), ('that', 'and'), ('and', 'like'), ('like', 't'), ('t', '...'), ('...', '44'), ('44', 'part'), ('part', 'i'), ('i', 'arose\\\\n\\\\nif'), ('arose\\\\n\\\\nif', 'i'), ('i', 'could'), ('could', 'rewind'), ('rewind', 'time'), ('time', 'like'), ('like', 'a'), ('a', '...'), ('...', '80'), ('80', 'intro'), ('intro', '50'), ('50', 'cent'), ('cent', 'eminem'), ('eminem', 'green'), ('green', 'lantern\\\\nyeah\\\\nshad'), ('lantern\\\\nyeah\\\\nshad', '...'), ('...', '57'), ('57', 'intro\\\\nya'), ('intro\\\\nya', 'we'), ('we', 'gots'), ('gots', 'money'), ('money', 'baby'), ('baby', 'i'), ('i', \"'m\"), (\"'m\", 'talking'), ('talking', 'about'), ('about', '...'), ('...', '10'), ('10', 'verse'), ('verse', '1'), ('1', 'royce'), ('royce', 'da'), ('da', '5'), ('5', \"'\"), (\"'\", '9\\\\nryan'), ('9\\\\nryan', \"'s\"), (\"'s\", 'a'), ('a', 'homicidal'), ('homicidal', 'misfi'), ('misfi', '...'), ('...', 'name'), ('name', ':'), (':', 'song'), ('song', 'lyrics'), ('lyrics', ','), (',', 'length'), ('length', ':'), (':', '70'), ('70', ','), (',', 'dtype'), ('dtype', ':'), (':', 'object')]\n"
     ]
    }
   ],
   "source": [
    "test1 = str(test['Song lyrics'])\n",
    "test1=test1.lower()\n",
    "test1.split(\"\\n\")\n",
    "tok = nltk.word_tokenize(test1)\n",
    "bigr = nltk.bigrams(tok)\n",
    "print(list(bigr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'to', 'kick', '...', '67', 'intro', 'dj', 'green', 'lantern', 'eminem\\\\nfucker\\\\nyeah\\\\n', '...', '45', 'verse', '1', 'eminem\\\\ncame', 'to', 'the', 'world', 'at', 'a']\n"
     ]
    }
   ],
   "source": [
    "#больше похоже на пашу техника, конечно\n",
    "print(lm.generate(20, random_seed=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-365-ac6bc0d2abfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mperplexity\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \"\"\"\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_ngrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mentropy\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \"\"\"\n\u001b[0;32m    189\u001b[0m         return -1 * _mean(\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_ngrams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;34m\"\"\"Return average (aka mean) for sequence of items.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "lm.perplexity(bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavily based on:\n",
    "    https://www.kaggle.com/alvations/n-gram-language-model-with-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
